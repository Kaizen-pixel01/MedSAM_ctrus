{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Environment and MedSAM setup and  prep"
      ],
      "metadata": {
        "id": "1u2FaHTe-Dgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up collab runtime with gpu and mount the dirive to access the files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnzRlLd05y8a",
        "outputId": "cf19577b-70ac-4f66-845d-f940137930c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovi7iQfCyYfI",
        "outputId": "5ce3109a-afac-4fd8-fb01-13eeeee39028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MedSAM'...\n",
            "remote: Enumerating objects: 967, done.\u001b[K\n",
            "remote: Counting objects: 100% (354/354), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 967 (delta 286), reused 237 (delta 237), pack-reused 613 (from 2)\u001b[K\n",
            "Receiving objects: 100% (967/967), 62.89 MiB | 14.46 MiB/s, done.\n",
            "Resolving deltas: 100% (479/479), done.\n",
            "/content/MedSAM\n"
          ]
        }
      ],
      "source": [
        "# Clone the github repository\n",
        "!git clone https://github.com/bowang-lab/MedSAM.git\n",
        "%cd MedSAM\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MedSAM as a package - following readme from github\n",
        "!pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2gkg-sYj5_8t",
        "outputId": "7b17d580-ea95-4258-c0c7-022538d58bc0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/MedSAM\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from medsam==0.0.1) (3.10.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medsam==0.0.1) (0.25.2)\n",
            "Collecting SimpleITK>=2.2.1 (from medsam==0.0.1)\n",
            "  Downloading simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from medsam==0.0.1) (5.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medsam==0.0.1) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from medsam==0.0.1) (1.16.1)\n",
            "Collecting ipympl (from medsam==0.0.1)\n",
            "  Downloading ipympl-0.9.7-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from medsam==0.0.1) (4.12.0.88)\n",
            "Collecting jupyterlab (from medsam==0.0.1)\n",
            "  Downloading jupyterlab-4.4.6-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from medsam==0.0.1) (7.7.1)\n",
            "Requirement already satisfied: ipython<10 in /usr/local/lib/python3.11/dist-packages (from ipympl->medsam==0.0.1) (7.34.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ipympl->medsam==0.0.1) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from ipympl->medsam==0.0.1) (11.3.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.11/dist-packages (from ipympl->medsam==0.0.1) (5.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->medsam==0.0.1) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->medsam==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->medsam==0.0.1) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->medsam==0.0.1) (3.0.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->medsam==0.0.1) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->medsam==0.0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->medsam==0.0.1) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->medsam==0.0.1) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->medsam==0.0.1) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->medsam==0.0.1) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->medsam==0.0.1) (2.9.0.post0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->medsam==0.0.1)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->medsam==0.0.1) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->medsam==0.0.1) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->medsam==0.0.1) (5.8.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->medsam==0.0.1)\n",
            "  Downloading jupyter_lsp-2.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->medsam==0.0.1)\n",
            "  Downloading jupyter_server-2.16.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->medsam==0.0.1)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->medsam==0.0.1) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->medsam==0.0.1) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->medsam==0.0.1) (6.4.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->medsam==0.0.1) (6.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel->medsam==0.0.1) (4.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medsam==0.0.1) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medsam==0.0.1) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medsam==0.0.1) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medsam==0.0.1) (0.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab->medsam==0.0.1) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab->medsam==0.0.1) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab->medsam==0.0.1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab->medsam==0.0.1) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->medsam==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->medsam==0.0.1) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->medsam==0.0.1) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->medsam==0.0.1) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->medsam==0.0.1) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->medsam==0.0.1) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->medsam==0.0.1) (26.2.1)\n",
            "Collecting jedi>=0.16 (from ipython<10->ipympl->medsam==0.0.1)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->medsam==0.0.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->medsam==0.0.1) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->medsam==0.0.1) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->medsam==0.0.1) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->medsam==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->medsam==0.0.1) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab->medsam==0.0.1) (3.0.2)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (25.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=4.5.1->ipywidgets->medsam==0.0.1)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (0.22.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (1.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->medsam==0.0.1) (4.3.8)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->medsam==0.0.1) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->medsam==0.0.1)\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->medsam==0.0.1) (4.25.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->medsam==0.0.1) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->medsam==0.0.1) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->medsam==0.0.1) (6.5.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->medsam==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (25.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<10->ipympl->medsam==0.0.1) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->medsam==0.0.1) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->medsam==0.0.1) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->medsam==0.0.1) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->medsam==0.0.1) (0.27.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (2.21.1)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=4.5.1->ipywidgets->medsam==0.0.1)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->medsam==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->medsam==0.0.1) (0.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<10->ipympl->medsam==0.0.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<10->ipympl->medsam==0.0.1) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->medsam==0.0.1) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->medsam==0.0.1) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (1.4.0)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (3.0.0)\n",
            "Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (24.11.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1) (2.22)\n",
            "Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->medsam==0.0.1)\n",
            "  Downloading types_python_dateutil-2.9.0.20250809-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipympl-0.9.7-py3-none-any.whl (515 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.7/515.7 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.4.6-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.2.6-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.4/69.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.16.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20250809-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: SimpleITK, uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, lark, json5, jedi, fqdn, async-lru, rfc3987-syntax, jupyter-server-terminals, jupyter-client, arrow, isoduration, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, ipympl, medsam\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "  Running setup.py develop for medsam\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires jupyter-server==1.16.0, but you have jupyter-server 2.16.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SimpleITK-2.5.2 arrow-1.3.0 async-lru-2.0.5 fqdn-1.5.1 ipympl-0.9.7 isoduration-20.11.0 jedi-0.19.2 json5-0.12.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.6 jupyter-server-2.16.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.6 jupyterlab-server-2.27.3 lark-1.2.2 medsam-0.0.1 overrides-7.7.0 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 types-python-dateutil-2.9.0.20250809 uri-template-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking to make sure the file location exists for checkpoint\n",
        "import os\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/MedSAM/work_dir/MedSAM/medsam_vit_b.pth'\n",
        "print(\"Checkpoint exists:\", os.path.exists(checkpoint_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15yuMqCg6S-m",
        "outputId": "d2b8586f-dd0e-4dd4-bacd-554251260aa5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Copy pretrained checkpoint to MedSAM dir\n",
        "!mkdir -p work_dir/MedSAM\n",
        "!cp /content/drive/MyDrive/MedSAM/work_dir/MedSAM/medsam_vit_b.pth work_dir/MedSAM/\n"
      ],
      "metadata": {
        "id": "4cV-JwAi6WxR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Have to convert the jpg to npy since that is the input expected by MedSAM - starting with a small sample size of images to test and make sure model works (15 images)\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm #to see progress\n",
        "\n",
        "def convert_jpg_to_npy(image_dir, mask_dir, output_img_dir, output_mask_dir):\n",
        "    os.makedirs(output_img_dir, exist_ok=True)\n",
        "    os.makedirs(output_mask_dir, exist_ok=True)\n",
        "\n",
        "    image_names = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "    #need to load image and mask and have them resized to match the training script for MedSAM (from MedSAM's github) so that it will work with the model\n",
        "    for name in tqdm(image_names):\n",
        "        # Loading and normalizing image\n",
        "        img = cv2.imread(os.path.join(image_dir, name))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_resized = cv2.resize(img, (1024, 1024), interpolation=cv2.INTER_CUBIC)\n",
        "        img_norm = img_resized.astype(np.float32) / 255.0 #for white\n",
        "        np.save(os.path.join(output_img_dir, name.replace('.jpg', '.npy')), img_norm)\n",
        "\n",
        "        # need to binarize mask\n",
        "        mask = cv2.imread(os.path.join(mask_dir, name), cv2.IMREAD_GRAYSCALE)\n",
        "        mask_resized = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
        "        mask_bin = (mask_resized > 0).astype(np.uint8) #for 0 or 1 same as training script\n",
        "        np.save(os.path.join(output_mask_dir, name.replace('.jpg', '.npy')), mask_bin)\n",
        "\n",
        "    print(\" Finished converting images and masks to .npy format\")\n",
        "\n",
        "# Run conversion with correct Drive paths (this is why you have to make sure that the files I mentioned in the MRP GitHub are placed appropriately)\n",
        "convert_jpg_to_npy(\n",
        "    image_dir='/content/drive/MyDrive/MedSAM/data/ctrus_sample/images',\n",
        "    mask_dir='/content/drive/MyDrive/MedSAM/data/ctrus_sample/masks',\n",
        "    output_img_dir='/content/MedSAM/data/npy_sample/imgs',\n",
        "    output_mask_dir='/content/MedSAM/data/npy_sample/gts'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOY7MXuC8gEH",
        "outputId": "bf265449-6eed-4bc0-b707-dc60a12c2a9e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:26<00:00,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Finished converting images and masks to .npy format\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries needed to run training with MedSAM\n",
        "!pip install monai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPSBGBOv9dyl",
        "outputId": "e78e187a-5bda-4f4c-a595-3bbaa157f574",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (2.0.2)\n",
            "Requirement already satisfied: torch<2.7.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.7.0,>=2.4.1->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.7.0,>=2.4.1->monai) (3.0.2)\n",
            "Downloading monai-1.5.0-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed monai-1.5.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with one gpu on the sample image-mask pairs to test the model before moving on with full dataset\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/train_one_gpu_medsam_with_evaluation_collab.py \\\n",
        "  -i /content/MedSAM/data/npy_sample \\\n",
        "  -checkpoint work_dir/MedSAM/medsam_vit_b.pth \\\n",
        "  --device cuda \\\n",
        "  -num_epochs 5 \\\n",
        "  -batch_size 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI1pOZWu9XYU",
        "outputId": "61501e20-8e09-4792-ccaf-59c20f463c87"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-17 20:28:03.696814: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755462483.926370    6248 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755462483.990920    6248 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755462484.467162    6248 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755462484.467200    6248 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755462484.467204    6248 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755462484.467209    6248 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-17 20:28:04.513838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✅ Number of image-mask pairs: 15\n",
            "100% 15/15 [00:17<00:00,  1.17s/it]\n",
            "Epoch 0: Loss = 1.2282\n",
            "Epoch 0 Metrics -> Dice: 0.0000, IoU: 0.0000, Precision: 0.0000, Recall: 0.0000\n",
            "100% 15/15 [00:16<00:00,  1.10s/it]\n",
            "Epoch 1: Loss = 0.8992\n",
            "Epoch 1 Metrics -> Dice: 0.1212, IoU: 0.0694, Precision: 0.1466, Recall: 0.1719\n",
            "100% 15/15 [00:16<00:00,  1.12s/it]\n",
            "Epoch 2: Loss = 0.5806\n",
            "Epoch 2 Metrics -> Dice: 0.4404, IoU: 0.3059, Precision: 0.4452, Recall: 0.5544\n",
            "100% 15/15 [00:16<00:00,  1.13s/it]\n",
            "Epoch 3: Loss = 0.4099\n",
            "Epoch 3 Metrics -> Dice: 0.6091, IoU: 0.4585, Precision: 0.7001, Recall: 0.6590\n",
            "100% 15/15 [00:17<00:00,  1.16s/it]\n",
            "Epoch 4: Loss = 0.4979\n",
            "Epoch 4 Metrics -> Dice: 0.5644, IoU: 0.4258, Precision: 0.7014, Recall: 0.6734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only need to run the following cell if it is the first time creating a dir for the training group (with small sample size for testing)\n"
      ],
      "metadata": {
        "id": "1Wjbiun4nl4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Now ill look at using different training groups according to the experiments (keeping to the smaller sample sizes in order to test the\n",
        "### models and make sure it works properly before conducting it on the entire dataset)\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from shutil import copyfile\n",
        "\n",
        "# Paths\n",
        "csv_path = '/content/drive/MyDrive/MedSAM/data/ctrus/c-trus.filtered.csv'\n",
        "image_dir = '/content/drive/MyDrive/MedSAM/data/ctrus/images'\n",
        "mask_dir = '/content/drive/MyDrive/MedSAM/data/ctrus/masks'\n",
        "\n",
        "# Saving to google drive so it persists\n",
        "output_image_dir = '/content/drive/MyDrive/MedSAM/data/high_quality_sample/images'\n",
        "output_mask_dir = '/content/drive/MyDrive/MedSAM/data/high_quality_sample/masks'\n",
        "\n",
        "#Create output folders\n",
        "os.makedirs(output_image_dir, exist_ok=True)\n",
        "os.makedirs(output_mask_dir, exist_ok=True)\n",
        "\n",
        "# Load filtered CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Select only high-quality images\n",
        "hq_df = df[df['quality'] == 0]\n",
        "print(f\" Found {len(hq_df)} high-quality images\")\n",
        "\n",
        "# Limitng to 15 for balanced comparison\n",
        "hq_df = hq_df.head(15)\n",
        "\n",
        "# Copy files\n",
        "for fname in hq_df['file']:\n",
        "    src_img = os.path.join(image_dir, fname)\n",
        "    src_mask = os.path.join(mask_dir, fname)\n",
        "    dst_img = os.path.join(output_image_dir, fname)\n",
        "    dst_mask = os.path.join(output_mask_dir, fname)\n",
        "\n",
        "    if os.path.exists(src_img) and os.path.exists(src_mask):\n",
        "        copyfile(src_img, dst_img)\n",
        "        copyfile(src_mask, dst_mask)\n",
        "        print(f\"Copied {fname}\")\n",
        "    else:\n",
        "        print(f\"Skipped {fname} (missing)\")\n",
        "\n",
        "print(\"Done copying high-quality samples to Google Drive.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3i52zV6km8X",
        "outputId": "76ef92a9-c4ca-4d2f-eb1a-b693e61908a3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Found 170 high-quality images\n",
            "Copied E26MT6C.jpg\n",
            "Copied AQY3DE2.jpg\n",
            "Copied 0311XXS.jpg\n",
            "Copied XIHLEX6.jpg\n",
            "Copied ZMMN2NR.jpg\n",
            "Copied VIN02HN.jpg\n",
            "Copied 0MVW1GD.jpg\n",
            "Copied ESN816N.jpg\n",
            "Copied 4PK5KEG.jpg\n",
            "Copied H29LQ2S.jpg\n",
            "Copied MIQ5791.jpg\n",
            "Copied HXCL6TN.jpg\n",
            "Copied BDI4WIR.jpg\n",
            "Copied P94IESQ.jpg\n",
            "Copied Z41418X.jpg\n",
            "Done copying high-quality samples to Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now i can use the previously used function to convert jpg to npy for the new group of images\n",
        "convert_jpg_to_npy(\n",
        "    image_dir='/content/drive/MyDrive/MedSAM/data/high_quality_sample/images',\n",
        "    mask_dir='/content/drive/MyDrive/MedSAM/data/high_quality_sample/masks',\n",
        "    output_img_dir='/content/MedSAM/data/npy_high/imgs',\n",
        "    output_mask_dir='/content/MedSAM/data/npy_high/gts'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MZqINhcna4Y",
        "outputId": "5e0dcf0d-0894-4207-a117-1d25582d3ba8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:00<00:00, 17.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Finished converting images and masks to .npy format\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tuning MedSam with the new training group\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/train_one_gpu_medsam_with_evaluation_collab.py \\\n",
        "  -i /content/MedSAM/data/npy_high \\\n",
        "  -checkpoint work_dir/MedSAM/medsam_vit_b.pth \\\n",
        "  --device cuda \\\n",
        "  -num_epochs 5 \\\n",
        "  -batch_size 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VxL8ZdzoCWK",
        "outputId": "e590f806-f368-4d6f-b4be-14921cabd6d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-17 20:32:51.193266: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755462771.214877    7583 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755462771.221195    7583 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755462771.237370    7583 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755462771.237395    7583 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755462771.237399    7583 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755462771.237403    7583 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-17 20:32:51.242162: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✅ Number of image-mask pairs: 15\n",
            "100% 15/15 [00:17<00:00,  1.15s/it]\n",
            "Epoch 0: Loss = 1.2895\n",
            "Epoch 0 Metrics -> Dice: 0.0047, IoU: 0.0024, Precision: 0.0108, Recall: 0.0030\n",
            "100% 15/15 [00:17<00:00,  1.17s/it]\n",
            "Epoch 1: Loss = 0.8093\n",
            "Epoch 1 Metrics -> Dice: 0.1675, IoU: 0.1136, Precision: 0.1939, Recall: 0.1761\n",
            "100% 15/15 [00:17<00:00,  1.19s/it]\n",
            "Epoch 2: Loss = 0.3633\n",
            "Epoch 2 Metrics -> Dice: 0.7010, IoU: 0.5542, Precision: 0.6953, Recall: 0.7627\n",
            "100% 15/15 [00:17<00:00,  1.19s/it]\n",
            "Epoch 3: Loss = 0.2927\n",
            "Epoch 3 Metrics -> Dice: 0.7516, IoU: 0.6144, Precision: 0.7705, Recall: 0.8080\n",
            "100% 15/15 [00:17<00:00,  1.17s/it]\n",
            "Epoch 4: Loss = 0.1981\n",
            "Epoch 4 Metrics -> Dice: 0.8314, IoU: 0.7182, Precision: 0.8175, Recall: 0.8709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After checking if the sample above works with the rest of the code then you can use the whole dataset to make final training group\n",
        "import os\n",
        "import pandas as pd\n",
        "from shutil import copyfile\n",
        "\n",
        "# Paths\n",
        "csv_path = '/content/drive/MyDrive/MedSAM/data/ctrus/c-trus.filtered.csv'\n",
        "image_dir = '/content/drive/MyDrive/MedSAM/data/ctrus/images'\n",
        "mask_dir = '/content/drive/MyDrive/MedSAM/data/ctrus/masks'\n",
        "\n",
        "# Saving persistent location in google drive\n",
        "output_image_dir = '/content/drive/MyDrive/MedSAM/data/high_quality_full/images'\n",
        "output_mask_dir = '/content/drive/MyDrive/MedSAM/data/high_quality_full/masks'\n",
        "\n",
        "# Create output folders\n",
        "os.makedirs(output_image_dir, exist_ok=True)\n",
        "os.makedirs(output_mask_dir, exist_ok=True)\n",
        "\n",
        "# Load filtered CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Getting all high-quality images\n",
        "hq_df = df[df['quality'] == 0]\n",
        "print(f\"Found {len(hq_df)} high-quality images\")\n",
        "\n",
        "# Copy files (skip if already copied)\n",
        "copied, skipped = 0, 0\n",
        "for fname in hq_df['file']:\n",
        "    src_img = os.path.join(image_dir, fname)\n",
        "    src_mask = os.path.join(mask_dir, fname)\n",
        "    dst_img = os.path.join(output_image_dir, fname)\n",
        "    dst_mask = os.path.join(output_mask_dir, fname)\n",
        "\n",
        "    if os.path.exists(src_img) and os.path.exists(src_mask):\n",
        "        if not os.path.exists(dst_img):\n",
        "            copyfile(src_img, dst_img)\n",
        "            copyfile(src_mask, dst_mask)\n",
        "            copied += 1\n",
        "        else:\n",
        "            skipped += 1\n",
        "    else:\n",
        "        print(f\" Missing {fname}\")\n",
        "\n",
        "print(f\" Done. Copied: {copied}, Skipped (already exist): {skipped}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkr6r9CtCNZf",
        "outputId": "4e64c8ca-1d26-4ea7-f008-c12e4a720eca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 170 high-quality images\n",
            " Done. Copied: 0, Skipped (already exist): 170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same conversion but with full dataset\n",
        "convert_jpg_to_npy(\n",
        "    image_dir='/content/drive/MyDrive/MedSAM/data/high_quality_full/images',\n",
        "    mask_dir='/content/drive/MyDrive/MedSAM/data/high_quality_full/masks',\n",
        "    output_img_dir = '/content/drive/MyDrive/MedSAM/data/npy_high_full/imgs',\n",
        "    output_mask_dir = '/content/drive/MyDrive/MedSAM/data/npy_high_full/gts'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRsAVCBdCjQE",
        "outputId": "25391ccf-41af-4728-d7bb-8c40bcf04860"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170/170 [07:54<00:00,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Finished converting images and masks to .npy format\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the training script saves the trained path locally I need to save it to the drive so that it doesnt need to be rerun every time the runtime is reset\n",
        "!mkdir -p /content/drive/MyDrive/MedSAM/work_dir/MedSAM\n",
        "\n",
        "!mkdir -p /content/work_dir  # ensure parent directory exists\n",
        "!ln -s /content/drive/MyDrive/MedSAM/work_dir/MedSAM /content/work_dir/MedSAM\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7W9llpjmPosO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not need to run every time if you have already run it once and have the best path saved to drive\n",
        "#use the full high quality set for training - using the same script but with change so that it saves the trained model sheckpoint since it will be used in experiments\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/train_one_gpu_medsam_with_evaluation_collab.py \\\n",
        "  -i /content/drive/MyDrive/MedSAM/data/npy_high_full \\\n",
        "  -checkpoint work_dir/MedSAM/medsam_vit_b.pth \\\n",
        "  --device cuda \\\n",
        "  -num_epochs 20 \\\n",
        "  -batch_size 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_04OhweHED9j",
        "outputId": "ce0e7a10-1ca7-49c4-ba59-dfefae2d615e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-26 18:27:39.233006: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753554459.253808   26225 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753554459.260003   26225 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-26 18:27:39.281108: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✅ Number of image-mask pairs: 170\n",
            "100% 170/170 [03:41<00:00,  1.30s/it]\n",
            "Epoch 0: Loss = 0.4533\n",
            "Epoch 0 Metrics -> Dice: 0.6078, IoU: 0.4930, Precision: 0.6162, Recall: 0.6476\n",
            "100% 170/170 [03:45<00:00,  1.33s/it]\n",
            "Epoch 1: Loss = 0.2100\n",
            "Epoch 1 Metrics -> Dice: 0.8130, IoU: 0.6988, Precision: 0.8002, Recall: 0.8504\n",
            "100% 170/170 [04:00<00:00,  1.41s/it]\n",
            "Epoch 2: Loss = 0.1712\n",
            "Epoch 2 Metrics -> Dice: 0.8442, IoU: 0.7413, Precision: 0.8353, Recall: 0.8704\n",
            "100% 170/170 [03:59<00:00,  1.41s/it]\n",
            "Epoch 3: Loss = 0.1565\n",
            "Epoch 3 Metrics -> Dice: 0.8577, IoU: 0.7591, Precision: 0.8491, Recall: 0.8803\n",
            "100% 170/170 [03:59<00:00,  1.41s/it]\n",
            "Epoch 4: Loss = 0.1350\n",
            "Epoch 4 Metrics -> Dice: 0.8750, IoU: 0.7833, Precision: 0.8697, Recall: 0.8895\n",
            "100% 170/170 [04:00<00:00,  1.41s/it]\n",
            "Epoch 5: Loss = 0.1153\n",
            "Epoch 5 Metrics -> Dice: 0.8905, IoU: 0.8066, Precision: 0.8860, Recall: 0.8995\n",
            "100% 170/170 [03:59<00:00,  1.41s/it]\n",
            "Epoch 6: Loss = 0.1019\n",
            "Epoch 6 Metrics -> Dice: 0.9010, IoU: 0.8230, Precision: 0.8988, Recall: 0.9059\n",
            "100% 170/170 [03:59<00:00,  1.41s/it]\n",
            "Epoch 7: Loss = 0.0976\n",
            "Epoch 7 Metrics -> Dice: 0.9037, IoU: 0.8277, Precision: 0.9049, Recall: 0.9064\n",
            "100% 170/170 [04:00<00:00,  1.41s/it]\n",
            "Epoch 8: Loss = 0.0889\n",
            "Epoch 8 Metrics -> Dice: 0.9108, IoU: 0.8387, Precision: 0.9134, Recall: 0.9105\n",
            "100% 170/170 [03:59<00:00,  1.41s/it]\n",
            "Epoch 9: Loss = 0.0852\n",
            "Epoch 9 Metrics -> Dice: 0.9129, IoU: 0.8426, Precision: 0.9156, Recall: 0.9124\n",
            "100% 170/170 [04:00<00:00,  1.41s/it]\n",
            "Epoch 10: Loss = 0.0798\n",
            "Epoch 10 Metrics -> Dice: 0.9177, IoU: 0.8501, Precision: 0.9222, Recall: 0.9153\n",
            "100% 170/170 [04:00<00:00,  1.41s/it]\n",
            "Epoch 11: Loss = 0.0760\n",
            "Epoch 11 Metrics -> Dice: 0.9205, IoU: 0.8549, Precision: 0.9227, Recall: 0.9199\n",
            "100% 170/170 [03:59<00:00,  1.41s/it]\n",
            "Epoch 12: Loss = 0.0718\n",
            "Epoch 12 Metrics -> Dice: 0.9241, IoU: 0.8609, Precision: 0.9253, Recall: 0.9243\n",
            "100% 170/170 [03:59<00:00,  1.41s/it]\n",
            "Epoch 13: Loss = 0.0693\n",
            "Epoch 13 Metrics -> Dice: 0.9264, IoU: 0.8649, Precision: 0.9276, Recall: 0.9271\n",
            "100% 170/170 [04:00<00:00,  1.41s/it]\n",
            "Epoch 14: Loss = 0.0671\n",
            "Epoch 14 Metrics -> Dice: 0.9289, IoU: 0.8690, Precision: 0.9298, Recall: 0.9296\n",
            "100% 170/170 [04:00<00:00,  1.42s/it]\n",
            "Epoch 15: Loss = 0.0638\n",
            "Epoch 15 Metrics -> Dice: 0.9326, IoU: 0.8751, Precision: 0.9314, Recall: 0.9352\n",
            "100% 170/170 [04:00<00:00,  1.41s/it]\n",
            "Epoch 16: Loss = 0.0602\n",
            "Epoch 16 Metrics -> Dice: 0.9365, IoU: 0.8819, Precision: 0.9340, Recall: 0.9402\n",
            "100% 170/170 [04:00<00:00,  1.41s/it]\n",
            "Epoch 17: Loss = 0.0599\n",
            "Epoch 17 Metrics -> Dice: 0.9375, IoU: 0.8839, Precision: 0.9373, Recall: 0.9395\n",
            "100% 170/170 [04:00<00:00,  1.41s/it]\n",
            "Epoch 18: Loss = 0.0588\n",
            "Epoch 18 Metrics -> Dice: 0.9400, IoU: 0.8886, Precision: 0.9373, Recall: 0.9438\n",
            "100% 170/170 [04:00<00:00,  1.42s/it]\n",
            "Epoch 19: Loss = 0.0538\n",
            "Epoch 19 Metrics -> Dice: 0.9442, IoU: 0.8959, Precision: 0.9414, Recall: 0.9484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 1: Filter Low-Quality Samples"
      ],
      "metadata": {
        "id": "C88JpPgg-OsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load metadata and filter low-quality samples\n",
        "csv_path = \"/content/drive/MyDrive/MedSAM/data/ctrus/c-trus.filtered.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Filter rows where quality_name is 'low'\n",
        "df_low = df[df['quality_name'] == 'low']\n",
        "low_quality_filenames = df_low['file'].tolist()\n",
        "\n",
        "print(\" Number of low-quality images found:\", len(low_quality_filenames))\n",
        "print(\"Sample filenames:\", low_quality_filenames[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kedxzp8L-USx",
        "outputId": "3fee36e5-10b6-465b-f3f5-f94d4beb6204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Number of low-quality images found: 93\n",
            "🖼️ Sample filenames: ['D1K2TQS.jpg', 'KSXTAWQ.jpg', 'R9Z0ECR.jpg', '62GWY4Y.jpg', '6LNEH6Y.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to copy low quality samples\n",
        "import os\n",
        "import pandas as pd\n",
        "from shutil import copyfile\n",
        "\n",
        "# Define paths\n",
        "csv_path = '/content/drive/MyDrive/MedSAM/data/ctrus/c-trus.filtered.csv'\n",
        "image_dir = '/content/drive/MyDrive/MedSAM/data/ctrus/images'\n",
        "mask_dir = '/content/drive/MyDrive/MedSAM/data/ctrus/masks'\n",
        "\n",
        "# Save to google drive (so its persistent)\n",
        "output_image_dir = '/content/drive/MyDrive/MedSAM/data/low_quality_sample/images'\n",
        "output_mask_dir = '/content/drive/MyDrive/MedSAM/data/low_quality_sample/masks'\n",
        "\n",
        "# Create output folders if they don't exist\n",
        "os.makedirs(output_image_dir, exist_ok=True)\n",
        "os.makedirs(output_mask_dir, exist_ok=True)\n",
        "\n",
        "# Load CSV and filter low-quality\n",
        "df = pd.read_csv(csv_path)\n",
        "low_df = df[df['quality_name'] == 'low']\n",
        "print(f\" Found {len(low_df)} low-quality images\")\n",
        "\n",
        "# Copy files only if not already present\n",
        "copied = 0\n",
        "skipped = 0\n",
        "for fname in low_df['file']:\n",
        "    src_img = os.path.join(image_dir, fname)\n",
        "    src_mask = os.path.join(mask_dir, fname)\n",
        "    dst_img = os.path.join(output_image_dir, fname)\n",
        "    dst_mask = os.path.join(output_mask_dir, fname)\n",
        "\n",
        "    if os.path.exists(src_img) and os.path.exists(src_mask):\n",
        "        if not os.path.exists(dst_img) and not os.path.exists(dst_mask):\n",
        "            copyfile(src_img, dst_img)\n",
        "            copyfile(src_mask, dst_mask)\n",
        "            copied += 1\n",
        "        else:\n",
        "            skipped += 1\n",
        "    else:\n",
        "        print(f\" Missing: {fname}\")\n",
        "\n",
        "print(f\" Done. Copied: {copied}, Skipped (already exist): {skipped}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkSsjC3S-87d",
        "outputId": "38f53bc6-c988-4e6f-df1a-ae542b32c1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Found 93 low-quality images\n",
            "✅ Done. Copied: 0, Skipped (already exist): 93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# function to convert to .npy (with debugging help)\n"
      ],
      "metadata": {
        "id": "cttH-TPFA6qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to .npy format for MedSAM input (using same function as before but with some safety checks for debugging)\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "def convert_jpg_to_npy(image_dir, mask_dir, output_img_dir, output_mask_dir):\n",
        "    os.makedirs(output_img_dir, exist_ok=True)\n",
        "    os.makedirs(output_mask_dir, exist_ok=True)\n",
        "\n",
        "    image_names = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "\n",
        "    print(f\" Found {len(image_names)} image–mask pairs to convert...\")\n",
        "\n",
        "    for name in tqdm(image_names):\n",
        "        img_path = os.path.join(image_dir, name)\n",
        "        mask_path = os.path.join(mask_dir, name)\n",
        "\n",
        "        if not os.path.exists(mask_path):\n",
        "            print(f\" Mask missing for {name}, skipping.\")\n",
        "            continue\n",
        "\n",
        "        #  Load and normalize image\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_resized = cv2.resize(img, (1024, 1024), interpolation=cv2.INTER_CUBIC)\n",
        "        img_norm = img_resized.astype(np.float32) / 255.0\n",
        "        np.save(os.path.join(output_img_dir, name.replace('.jpg', '.npy')), img_norm)\n",
        "\n",
        "        #  Load and binarize mask\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        mask_resized = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
        "        mask_bin = (mask_resized > 0).astype(np.uint8)\n",
        "        np.save(os.path.join(output_mask_dir, name.replace('.jpg', '.npy')), mask_bin)\n",
        "\n",
        "    print(\" Finished converting images and masks to .npy format\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3Sos73-BAEv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_jpg_to_npy(\n",
        "    image_dir='/content/drive/MyDrive/MedSAM/data/low_quality_sample/images',\n",
        "    mask_dir='/content/drive/MyDrive/MedSAM/data/low_quality_sample/masks',\n",
        "    output_img_dir='/content/MedSAM/data/npy_low/images',\n",
        "    output_mask_dir='/content/MedSAM/data/npy_low/masks'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EILV0bFEA4kl",
        "outputId": "73790c11-e9ac-40d6-bdbc-e8a5a6cbed20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Found 93 image–mask pairs to convert...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [02:41<00:00,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Finished converting images and masks to .npy format\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Will also upload to drive so that it can be accessed if needed without rerunning - also making the naming compatible for when training is done with low quality samples\n",
        "convert_jpg_to_npy(\n",
        "    image_dir='/content/drive/MyDrive/MedSAM/data/low_quality_sample/images',\n",
        "    mask_dir='/content/drive/MyDrive/MedSAM/data/low_quality_sample/masks',\n",
        "    output_img_dir='/content/drive/MyDrive/MedSAM/data/npy_low_full/imgs',\n",
        "    output_mask_dir='/content/drive/MyDrive/MedSAM/data/npy_low_full/gts'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55ON9vJmxw86",
        "outputId": "eb2cf54a-b7b2-4bd5-a259-20b5643ddc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Found 93 image–mask pairs to convert...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 93/93 [00:10<00:00,  9.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Finished converting images and masks to .npy format\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Made a script for the first experiment that loads the fine tuned model (using the high quality images) and will run inference on the low quality images to test MedSAM's performance\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_low_quality_eval_per.py \\\n",
        "  -data_path /content/MedSAM/data/npy_low \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250726-1827/medsam_model_best.pth \\\n",
        "  --device cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhuU5vSLUG_a",
        "outputId": "8e14e634-2a07-4294-8cbe-74e03b8197a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Found 93 image–mask pairs.\n",
            "100% 93/93 [00:41<00:00,  2.22it/s]\n",
            "📊 Evaluation Results: {'dice': 0.5104330785081832, 'iou': 0.36581054309342975, 'precision': 0.591249413668148, 'recall': 0.5157915496352499}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training for MedSAM on low quality images - needed for comparative analysis between both image quality groups (same process as high quality group training)\n"
      ],
      "metadata": {
        "id": "5NtHx6Cwy8oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Same training file but changing the input to low-quality images\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/train_one_gpu_medsam_with_evaluation_collab.py \\\n",
        "  -i /content/drive/MyDrive/MedSAM/data/npy_low_split/train \\\n",
        "  -checkpoint work_dir/MedSAM/medsam_vit_b.pth \\\n",
        "  --device cuda \\\n",
        "  -num_epochs 20 \\\n",
        "  -batch_size 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O6Isu_p4zJgH",
        "outputId": "c9bd2482-26d2-4474-87db-8e7ec5cb4da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-27 16:55:52.440679: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753635352.461777   15577 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753635352.468565   15577 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-27 16:55:52.490415: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✅ Number of image-mask pairs: 93\n",
            "100% 93/93 [01:50<00:00,  1.18s/it]\n",
            "Epoch 0: Loss = 0.7520\n",
            "Epoch 0 Metrics -> Dice: 0.3021, IoU: 0.2060, Precision: 0.3259, Recall: 0.3821\n",
            "100% 93/93 [01:53<00:00,  1.22s/it]\n",
            "Epoch 1: Loss = 0.4760\n",
            "Epoch 1 Metrics -> Dice: 0.5530, IoU: 0.4066, Precision: 0.5676, Recall: 0.6446\n",
            "100% 93/93 [02:08<00:00,  1.39s/it]\n",
            "Epoch 2: Loss = 0.2930\n",
            "Epoch 2 Metrics -> Dice: 0.7163, IoU: 0.5713, Precision: 0.7147, Recall: 0.7569\n",
            "100% 93/93 [02:05<00:00,  1.35s/it]\n",
            "Epoch 3: Loss = 0.2243\n",
            "Epoch 3 Metrics -> Dice: 0.7794, IoU: 0.6478, Precision: 0.7770, Recall: 0.8151\n",
            "100% 93/93 [02:06<00:00,  1.36s/it]\n",
            "Epoch 4: Loss = 0.1882\n",
            "Epoch 4 Metrics -> Dice: 0.8096, IoU: 0.6877, Precision: 0.8122, Recall: 0.8287\n",
            "100% 93/93 [02:07<00:00,  1.37s/it]\n",
            "Epoch 5: Loss = 0.1451\n",
            "Epoch 5 Metrics -> Dice: 0.8519, IoU: 0.7454, Precision: 0.8487, Recall: 0.8634\n",
            "100% 93/93 [02:08<00:00,  1.38s/it]\n",
            "Epoch 6: Loss = 0.1223\n",
            "Epoch 6 Metrics -> Dice: 0.8715, IoU: 0.7745, Precision: 0.8673, Recall: 0.8816\n",
            "100% 93/93 [02:08<00:00,  1.39s/it]\n",
            "Epoch 7: Loss = 0.1058\n",
            "Epoch 7 Metrics -> Dice: 0.8867, IoU: 0.7982, Precision: 0.8870, Recall: 0.8895\n",
            "100% 93/93 [02:06<00:00,  1.36s/it]\n",
            "Epoch 8: Loss = 0.0945\n",
            "Epoch 8 Metrics -> Dice: 0.8967, IoU: 0.8140, Precision: 0.9032, Recall: 0.8919\n",
            "100% 93/93 [02:07<00:00,  1.37s/it]\n",
            "Epoch 9: Loss = 0.0908\n",
            "Epoch 9 Metrics -> Dice: 0.9002, IoU: 0.8198, Precision: 0.9051, Recall: 0.8973\n",
            "100% 93/93 [02:08<00:00,  1.38s/it]\n",
            "Epoch 10: Loss = 0.0877\n",
            "Epoch 10 Metrics -> Dice: 0.9027, IoU: 0.8239, Precision: 0.9108, Recall: 0.8967\n",
            "100% 93/93 [02:06<00:00,  1.37s/it]\n",
            "Epoch 11: Loss = 0.0846\n",
            "Epoch 11 Metrics -> Dice: 0.9054, IoU: 0.8284, Precision: 0.9125, Recall: 0.9001\n",
            "100% 93/93 [02:06<00:00,  1.36s/it]\n",
            "Epoch 12: Loss = 0.0807\n",
            "Epoch 12 Metrics -> Dice: 0.9091, IoU: 0.8346, Precision: 0.9183, Recall: 0.9017\n",
            "100% 93/93 [02:06<00:00,  1.36s/it]\n",
            "Epoch 13: Loss = 0.0771\n",
            "Epoch 13 Metrics -> Dice: 0.9124, IoU: 0.8400, Precision: 0.9210, Recall: 0.9052\n",
            "100% 93/93 [02:07<00:00,  1.37s/it]\n",
            "Epoch 14: Loss = 0.0749\n",
            "Epoch 14 Metrics -> Dice: 0.9145, IoU: 0.8436, Precision: 0.9219, Recall: 0.9087\n",
            "100% 93/93 [02:06<00:00,  1.36s/it]\n",
            "Epoch 15: Loss = 0.0740\n",
            "Epoch 15 Metrics -> Dice: 0.9160, IoU: 0.8461, Precision: 0.9217, Recall: 0.9128\n",
            "100% 93/93 [02:06<00:00,  1.36s/it]\n",
            "Epoch 16: Loss = 0.0711\n",
            "Epoch 16 Metrics -> Dice: 0.9191, IoU: 0.8513, Precision: 0.9237, Recall: 0.9165\n",
            "100% 93/93 [02:09<00:00,  1.40s/it]\n",
            "Epoch 17: Loss = 0.0667\n",
            "Epoch 17 Metrics -> Dice: 0.9241, IoU: 0.8597, Precision: 0.9258, Recall: 0.9237\n",
            "100% 93/93 [02:08<00:00,  1.38s/it]\n",
            "Epoch 18: Loss = 0.0628\n",
            "Epoch 18 Metrics -> Dice: 0.9286, IoU: 0.8674, Precision: 0.9297, Recall: 0.9286\n",
            "100% 93/93 [02:07<00:00,  1.37s/it]\n",
            "Epoch 19: Loss = 0.0595\n",
            "Epoch 19 Metrics -> Dice: 0.9326, IoU: 0.8743, Precision: 0.9326, Recall: 0.9334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the experiment again but with the model trained on the low-quality images instead\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_low_quality_eval.py \\\n",
        "  -data_path /content/MedSAM/data/npy_low \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250727-1655/medsam_model_best.pth \\\n",
        "  --device cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSRtN-lH-pBb",
        "outputId": "15ea3411-23e1-4b8b-ccb7-7b9c3d9afd18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Found 93 image–mask pairs.\n",
            "100% 93/93 [00:40<00:00,  2.28it/s]\n",
            "📊 Evaluation Results: {'dice': 0.9345915804627121, 'iou': 0.8777359031861828, 'precision': 0.9352748208148505, 'recall': 0.9345902742878083}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Will also convert the full dataset to test along side the low-quality image test"
      ],
      "metadata": {
        "id": "oQ376SnUbl9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for only valid image mask pairs (same provcess as making filtered csv used earlier but I wanted to double check and I did it without relating to mask area to make sure)\n",
        "import os\n",
        "import cv2\n",
        "from shutil import copyfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Original dataset paths\n",
        "image_dir = '/content/drive/MyDrive/MedSAM/data/ctrus/images'\n",
        "mask_dir = '/content/drive/MyDrive/MedSAM/data/ctrus/masks'\n",
        "\n",
        "# Output paths\n",
        "output_image_dir = '/content/drive/MyDrive/MedSAM/data/filtered_full/images'\n",
        "output_mask_dir = '/content/drive/MyDrive/MedSAM/data/filtered_full/masks'\n",
        "\n",
        "# Output folders\n",
        "os.makedirs(output_image_dir, exist_ok=True)\n",
        "os.makedirs(output_mask_dir, exist_ok=True)\n",
        "\n",
        "# Filter valid image–mask pairs\n",
        "img_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg'))])\n",
        "valid_count = 0\n",
        "\n",
        "print(\" Filtering for non-empty masks...\")\n",
        "for fname in tqdm(img_files):\n",
        "    src_img = os.path.join(image_dir, fname)\n",
        "    src_mask = os.path.join(mask_dir, fname)\n",
        "\n",
        "    if not os.path.exists(src_mask):\n",
        "        continue\n",
        "\n",
        "    # Load and check mask to filter out the empty (all-black masks)\n",
        "    mask = cv2.imread(src_mask, cv2.IMREAD_GRAYSCALE)\n",
        "    if mask is not None and cv2.countNonZero(mask) > 0: #so it is considered valid since it is not empty\n",
        "        dst_img = os.path.join(output_image_dir, fname) # it just uses fname to copy the valid image mask pairs into the filtered folder\n",
        "        dst_mask = os.path.join(output_mask_dir, fname)\n",
        "        copyfile(src_img, dst_img)\n",
        "        copyfile(src_mask, dst_mask)\n",
        "        valid_count += 1\n",
        "\n",
        "print(f\" Done. Copied {valid_count} valid image–mask pairs to 'filtered_full'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlTJ-AUBbkSG",
        "outputId": "ace7b559-e7b8-47ad-853e-f747f33c634f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Filtering for non-empty masks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 827/827 [00:25<00:00, 32.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Done. Copied 508 valid image–mask pairs to 'filtered_full'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to convert to .npy as well\n",
        "convert_jpg_to_npy(\n",
        "    image_dir='/content/drive/MyDrive/MedSAM/data/filtered_full/images',\n",
        "    mask_dir='/content/drive/MyDrive/MedSAM/data/filtered_full/masks',\n",
        "    output_img_dir='/content/drive/MyDrive/MedSAM/data/npy_filtered_full/imgs',\n",
        "    output_mask_dir='/content/drive/MyDrive/MedSAM/data/npy_filtered_full/gts'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JC880kEg8ic",
        "outputId": "0e12909a-4529-45ed-a5d7-1fde26c3a494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 508/508 [00:58<00:00,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Finished converting images and masks to .npy format\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When conducting the experiments, I realized the need for a seperate set of images to be used (since the model trained on the low-quality images will not be tested on unseen images). So i have split the low-quality images into two groups so that one can be used for training and the other for testing.\n"
      ],
      "metadata": {
        "id": "Nen3Ih8pUhyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a split of the data to be used\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Paths for source as well as well as folders to split the low-quality images into train and test splits\n",
        "src_img_dir = '/content/drive/MyDrive/MedSAM/data/npy_low_full/imgs'\n",
        "src_mask_dir = '/content/drive/MyDrive/MedSAM/data/npy_low_full/gts'\n",
        "\n",
        "train_img_dir = '/content/drive/MyDrive/MedSAM/data/npy_low_split/train/imgs'\n",
        "train_mask_dir = '/content/drive/MyDrive/MedSAM/data/npy_low_split/train/gts'\n",
        "test_img_dir = '/content/drive/MyDrive/MedSAM/data/npy_low_split/test/imgs'\n",
        "test_mask_dir = '/content/drive/MyDrive/MedSAM/data/npy_low_split/test/gts'\n",
        "\n",
        "# Creating output folders to match\n",
        "os.makedirs(train_img_dir, exist_ok=True)\n",
        "os.makedirs(train_mask_dir, exist_ok=True)\n",
        "os.makedirs(test_img_dir, exist_ok=True)\n",
        "os.makedirs(test_mask_dir, exist_ok=True)\n",
        "\n",
        "# List all .npy files\n",
        "all_files = [f for f in os.listdir(src_img_dir) if f.endswith('.npy')]\n",
        "random.seed(42) # to make it reproducable so that if you run this it should result in the same split as me so the results should match\n",
        "random.shuffle(all_files) # shuffling\n",
        "\n",
        "# 70/30 split\n",
        "split_idx = int(len(all_files) * 0.7)\n",
        "train_files = all_files[:split_idx]\n",
        "test_files = all_files[split_idx:]\n",
        "\n",
        "print(f\" Splitting {len(all_files)} files into:\")\n",
        "print(f\" Train: {len(train_files)}\")\n",
        "print(f\" Test:  {len(test_files)}\")\n",
        "\n",
        "# To copy files - same approach as before\n",
        "def copy_split(files, img_dst, mask_dst):\n",
        "    for fname in files:\n",
        "        shutil.copy(os.path.join(src_img_dir, fname), os.path.join(img_dst, fname))\n",
        "        shutil.copy(os.path.join(src_mask_dir, fname), os.path.join(mask_dst, fname))\n",
        "\n",
        "# copy to train/test\n",
        "copy_split(train_files, train_img_dir, train_mask_dir)\n",
        "copy_split(test_files, test_img_dir, test_mask_dir)\n",
        "\n",
        "print(\" Split complete. Train/test sets saved in 'npy_low_split'.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw1wOGWlXwWe",
        "outputId": "d18ebdd8-be71-4df2-b015-b3ce299f8569"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Splitting 93 files into:\n",
            " Train: 65\n",
            " Test:  28\n",
            " Split complete. Train/test sets saved in 'npy_low_split'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TSrain again with the split low-quality images\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/train_one_gpu_medsam_with_evaluation_collab.py \\\n",
        "  -i /content/drive/MyDrive/MedSAM/data/npy_low_split/train \\\n",
        "  -checkpoint /content/drive/MyDrive/MedSAM/work_dir/MedSAM/medsam_vit_b.pth \\\n",
        "  --device cuda \\\n",
        "  -num_epochs 20 \\\n",
        "  -batch_size 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "822GIU8NlmYx",
        "outputId": "b64af13a-41fd-490f-d85b-5664a0159341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-28 19:52:05.780980: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753732326.065639   16824 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753732326.153330   16824 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-28 19:52:06.799992: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✅ Number of image-mask pairs: 65\n",
            "100% 65/65 [01:17<00:00,  1.19s/it]\n",
            "Epoch 0: Loss = 0.8594\n",
            "Epoch 0 Metrics -> Dice: 0.1885, IoU: 0.1272, Precision: 0.2011, Recall: 0.2527\n",
            "100% 65/65 [01:16<00:00,  1.18s/it]\n",
            "Epoch 1: Loss = 0.4677\n",
            "Epoch 1 Metrics -> Dice: 0.5474, IoU: 0.4041, Precision: 0.5563, Recall: 0.6100\n",
            "100% 65/65 [01:16<00:00,  1.17s/it]\n",
            "Epoch 2: Loss = 0.3090\n",
            "Epoch 2 Metrics -> Dice: 0.7106, IoU: 0.5661, Precision: 0.7113, Recall: 0.7724\n",
            "100% 65/65 [01:16<00:00,  1.18s/it]\n",
            "Epoch 3: Loss = 0.2207\n",
            "Epoch 3 Metrics -> Dice: 0.7847, IoU: 0.6560, Precision: 0.7718, Recall: 0.8297\n",
            "100% 65/65 [01:20<00:00,  1.24s/it]\n",
            "Epoch 4: Loss = 0.1841\n",
            "Epoch 4 Metrics -> Dice: 0.8162, IoU: 0.6956, Precision: 0.8175, Recall: 0.8372\n",
            "100% 65/65 [01:27<00:00,  1.34s/it]\n",
            "Epoch 5: Loss = 0.1594\n",
            "Epoch 5 Metrics -> Dice: 0.8408, IoU: 0.7286, Precision: 0.8312, Recall: 0.8650\n",
            "100% 65/65 [01:31<00:00,  1.40s/it]\n",
            "Epoch 6: Loss = 0.1312\n",
            "Epoch 6 Metrics -> Dice: 0.8645, IoU: 0.7650, Precision: 0.8570, Recall: 0.8825\n",
            "100% 65/65 [01:31<00:00,  1.41s/it]\n",
            "Epoch 7: Loss = 0.1143\n",
            "Epoch 7 Metrics -> Dice: 0.8804, IoU: 0.7882, Precision: 0.8754, Recall: 0.8920\n",
            "100% 65/65 [01:32<00:00,  1.42s/it]\n",
            "Epoch 8: Loss = 0.1017\n",
            "Epoch 8 Metrics -> Dice: 0.8912, IoU: 0.8054, Precision: 0.8905, Recall: 0.8955\n",
            "100% 65/65 [01:31<00:00,  1.40s/it]\n",
            "Epoch 9: Loss = 0.0943\n",
            "Epoch 9 Metrics -> Dice: 0.8980, IoU: 0.8163, Precision: 0.8974, Recall: 0.9009\n",
            "100% 65/65 [01:32<00:00,  1.43s/it]\n",
            "Epoch 10: Loss = 0.0903\n",
            "Epoch 10 Metrics -> Dice: 0.9011, IoU: 0.8211, Precision: 0.9010, Recall: 0.9032\n",
            "100% 65/65 [01:30<00:00,  1.40s/it]\n",
            "Epoch 11: Loss = 0.0861\n",
            "Epoch 11 Metrics -> Dice: 0.9050, IoU: 0.8276, Precision: 0.9091, Recall: 0.9026\n",
            "100% 65/65 [01:31<00:00,  1.41s/it]\n",
            "Epoch 12: Loss = 0.0836\n",
            "Epoch 12 Metrics -> Dice: 0.9069, IoU: 0.8309, Precision: 0.9085, Recall: 0.9072\n",
            "100% 65/65 [01:32<00:00,  1.42s/it]\n",
            "Epoch 13: Loss = 0.0818\n",
            "Epoch 13 Metrics -> Dice: 0.9087, IoU: 0.8337, Precision: 0.9129, Recall: 0.9065\n",
            "100% 65/65 [01:31<00:00,  1.41s/it]\n",
            "Epoch 14: Loss = 0.0799\n",
            "Epoch 14 Metrics -> Dice: 0.9105, IoU: 0.8368, Precision: 0.9153, Recall: 0.9082\n",
            "100% 65/65 [01:32<00:00,  1.42s/it]\n",
            "Epoch 15: Loss = 0.0771\n",
            "Epoch 15 Metrics -> Dice: 0.9125, IoU: 0.8401, Precision: 0.9179, Recall: 0.9088\n",
            "100% 65/65 [01:31<00:00,  1.41s/it]\n",
            "Epoch 16: Loss = 0.0759\n",
            "Epoch 16 Metrics -> Dice: 0.9145, IoU: 0.8435, Precision: 0.9190, Recall: 0.9128\n",
            "100% 65/65 [01:31<00:00,  1.40s/it]\n",
            "Epoch 17: Loss = 0.0740\n",
            "Epoch 17 Metrics -> Dice: 0.9164, IoU: 0.8467, Precision: 0.9188, Recall: 0.9164\n",
            "100% 65/65 [01:30<00:00,  1.40s/it]\n",
            "Epoch 18: Loss = 0.0698\n",
            "Epoch 18 Metrics -> Dice: 0.9201, IoU: 0.8529, Precision: 0.9238, Recall: 0.9179\n",
            "100% 65/65 [01:31<00:00,  1.40s/it]\n",
            "Epoch 19: Loss = 0.0677\n",
            "Epoch 19 Metrics -> Dice: 0.9226, IoU: 0.8572, Precision: 0.9264, Recall: 0.9207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 1 - Tests"
      ],
      "metadata": {
        "id": "tF-BeMTouSWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The models are tested on test split of low-quality images"
      ],
      "metadata": {
        "id": "TPN5yHG1EKPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running experiment with high-quality trained MedSAM\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_low_quality_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_low_split/test \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250726-high/medsam_model_best.pth \\\n",
        "  --device cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbISojS4Djrj",
        "outputId": "3fcf9a83-3637-43d2-cbd2-a0b137814aa0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Found 28 image–mask pairs.\n",
            "100% 28/28 [00:45<00:00,  1.62s/it]\n",
            "Evaluation Results: {'dice': 0.49488651586164323, 'iou': 0.3523703773639032, 'precision': 0.5449804830630975, 'recall': 0.5200350544681507}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#running experiment with low-quality trained MedSAM\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_low_quality_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_low_split/test \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250728-lowS/medsam_model_best.pth \\\n",
        "  --device cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhregmsKEqpo",
        "outputId": "9e69964d-8a7f-4132-f110-d71cf0f7ad1c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Found 28 image–mask pairs.\n",
            "100% 28/28 [00:14<00:00,  1.87it/s]\n",
            "Evaluation Results: {'dice': 0.4815975683087652, 'iou': 0.33079755838544334, 'precision': 0.5016562954673203, 'recall': 0.5644429938103965}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # DO NOT RUN THE FOLLOWING\n",
        " without having finished experiment 3 (this is used to help view differences in results it will give an error if you do not do that)"
      ],
      "metadata": {
        "id": "Pd07NwRHxs0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running experiment with mixed-quality trained MedSAM (this is from experiment 3 but I added it here to look at differences)\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_low_quality_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_low_split/test \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250728-mixedS/medsam_model_best.pth \\\n",
        "  --device cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMlUUB4KEq5v",
        "outputId": "72c5de7b-7b48-4807-dfe6-e5ddcdbabe6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Found 28 image–mask pairs.\n",
            "100% 28/28 [00:16<00:00,  1.69it/s]\n",
            "📊 Evaluation Results: {'dice': 0.4848139827538814, 'iou': 0.338812602184979, 'precision': 0.5526763663760254, 'recall': 0.5142066744821412}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 2: Noise Robustness Testing\n"
      ],
      "metadata": {
        "id": "4H85qe62Sz2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the experiments are done using the test split of low quality images (same format as above but going over experiment 1 test again to avoid potential variabce)"
      ],
      "metadata": {
        "id": "uB6xqyoLHUIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# High quality trained\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_noise_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_low_split/test \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250726-high/medsam_model_best.pth \\\n",
        "  --device cuda \\\n",
        "  --add_noise \\\n",
        "  --noise_variance 0.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyQmh_AUHYET",
        "outputId": "a990d0d8-4912-42ec-9c5d-6a35dc2eaa6c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28 image–mask pairs.\n",
            "100% 28/28 [00:19<00:00,  1.44it/s]\n",
            "Evaluation Results: {'dice': 4.501978483706767e-11, 'iou': 4.501978483706767e-11, 'precision': 0.9285714417077134, 'recall': 4.5031755048596005e-11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_noise_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_low_split/test \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250726-high/medsam_model_best.pth \\\n",
        "  --device cuda \\\n",
        "  --noise_variance 0.1"
      ],
      "metadata": {
        "id": "HQH0Ci4ZtNnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4ab79f-738b-45ca-a879-70052f4603ef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28 image–mask pairs.\n",
            "100% 28/28 [00:15<00:00,  1.78it/s]\n",
            "Evaluation Results: {'dice': 0.49488651586164323, 'iou': 0.3523703773639032, 'precision': 0.5449804830630975, 'recall': 0.5200350544681507}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Low quality trained\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_noise_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_low_split/test \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250728-lowS/medsam_model_best.pth \\\n",
        "  --device cuda \\\n",
        "  --add_noise \\\n",
        "  --noise_variance 0.1\n"
      ],
      "metadata": {
        "id": "rXeS-8kqHoJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44e0638-9001-4005-f39d-5c93684f6d5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28 image–mask pairs.\n",
            "100% 28/28 [00:20<00:00,  1.38it/s]\n",
            "Evaluation Results: {'dice': 0.005514042575159581, 'iou': 0.002854946435306393, 'precision': 0.55685350852101, 'recall': 0.0029052819099676464}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_noise_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_low_split/test \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250728-lowS/medsam_model_best.pth \\\n",
        "  --device cuda \\\n",
        "  --noise_variance 0.1"
      ],
      "metadata": {
        "id": "rZ2QYTkftPQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2e467f-2ff8-4d84-b2ec-d038698ce973"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28 image–mask pairs.\n",
            "100% 28/28 [00:16<00:00,  1.70it/s]\n",
            "Evaluation Results: {'dice': 0.4815975683087652, 'iou': 0.33079755838544334, 'precision': 0.5016562954673203, 'recall': 0.5644429938103965}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 3: Fine-tuning with mixed quality images - testing the strength of variety training in comparison to quality specific training"
      ],
      "metadata": {
        "id": "J42pldQ_vJ9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To train the model, we need to create the mixed folder containing the high and low quality images (making sure to have an even mix of the two image qualities to avoid training bias)\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "high_path = \"/content/drive/MyDrive/MedSAM/data/npy_high_full\"\n",
        "low_path = \"/content/drive/MyDrive/MedSAM/data/npy_low_split/train\"\n",
        "mixed_path = \"/content/drive/MyDrive/MedSAM/data/npy_mixedS\"\n",
        "mixed_imgs = os.path.join(mixed_path, \"imgs\")\n",
        "mixed_gts = os.path.join(mixed_path, \"gts\")\n",
        "\n",
        "os.makedirs(mixed_imgs, exist_ok=True)\n",
        "os.makedirs(mixed_gts, exist_ok=True)\n",
        "\n",
        "# Match number of low-quality samples - dont want to get bias in training\n",
        "low_files = os.listdir(os.path.join(low_path, \"imgs\"))\n",
        "high_files = os.listdir(os.path.join(high_path, \"imgs\"))\n",
        "random.seed(42)\n",
        "high_sample = random.sample(high_files, len(low_files))\n",
        "\n",
        "def copy_samples(file_list, src_img_dir, src_gt_dir, dst_img_dir, dst_gt_dir):\n",
        "    for fname in file_list:\n",
        "        shutil.copy(os.path.join(src_img_dir, fname), os.path.join(dst_img_dir, fname))\n",
        "        shutil.copy(os.path.join(src_gt_dir, fname), os.path.join(dst_gt_dir, fname))\n",
        "\n",
        "copy_samples(\n",
        "    file_list=low_files,\n",
        "    src_img_dir=os.path.join(low_path, \"imgs\"),\n",
        "    src_gt_dir=os.path.join(low_path, \"gts\"),\n",
        "    dst_img_dir=mixed_imgs,\n",
        "    dst_gt_dir=mixed_gts,\n",
        ")\n",
        "\n",
        "copy_samples(\n",
        "    file_list=high_sample,\n",
        "    src_img_dir=os.path.join(high_path, \"imgs\"),\n",
        "    src_gt_dir=os.path.join(high_path, \"gts\"),\n",
        "    dst_img_dir=mixed_imgs,\n",
        "    dst_gt_dir=mixed_gts,\n",
        ")\n",
        "\n",
        "print(f\" Created mixed-quality dataset at: {mixed_path}\")\n",
        "print(f\" {len(low_files)} low-quality + {len(high_sample)} high-quality samples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_-_CtUIvdL0",
        "outputId": "d6df5eb2-3657-4545-bc94-eb59b6d5a0e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Created mixed-quality dataset at: /content/drive/MyDrive/MedSAM/data/npy_mixedS\n",
            " 65 low-quality + 65 high-quality samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can run the same training script with the mized set of images\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/train_one_gpu_medsam_with_evaluation_collab.py \\\n",
        "  -i /content/drive/MyDrive/MedSAM/data/npy_mixedS \\\n",
        "  -checkpoint /content/drive/MyDrive/MedSAM/work_dir/MedSAM/medsam_vit_b.pth \\\n",
        "  --device cuda \\\n",
        "  -num_epochs 20 \\\n",
        "  -batch_size 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zxekjRQZEy26",
        "outputId": "64942b43-ad46-4a59-a8a9-ea972e200bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-28 20:41:37.091847: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753735297.366006   30358 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753735297.442380   30358 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-28 20:41:38.021989: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✅ Number of image-mask pairs: 130\n",
            "100% 130/130 [02:36<00:00,  1.20s/it]\n",
            "Epoch 0: Loss = 0.6356\n",
            "Epoch 0 Metrics -> Dice: 0.4330, IoU: 0.3233, Precision: 0.4658, Recall: 0.4996\n",
            "100% 130/130 [02:35<00:00,  1.20s/it]\n",
            "Epoch 1: Loss = 0.3348\n",
            "Epoch 1 Metrics -> Dice: 0.6916, IoU: 0.5597, Precision: 0.6958, Recall: 0.7655\n",
            "100% 130/130 [02:47<00:00,  1.29s/it]\n",
            "Epoch 2: Loss = 0.2307\n",
            "Epoch 2 Metrics -> Dice: 0.7839, IoU: 0.6601, Precision: 0.7809, Recall: 0.8222\n",
            "100% 130/130 [02:49<00:00,  1.31s/it]\n",
            "Epoch 3: Loss = 0.1813\n",
            "Epoch 3 Metrics -> Dice: 0.8310, IoU: 0.7208, Precision: 0.8255, Recall: 0.8560\n",
            "100% 130/130 [02:48<00:00,  1.30s/it]\n",
            "Epoch 4: Loss = 0.1466\n",
            "Epoch 4 Metrics -> Dice: 0.8574, IoU: 0.7570, Precision: 0.8512, Recall: 0.8781\n",
            "100% 130/130 [02:48<00:00,  1.29s/it]\n",
            "Epoch 5: Loss = 0.1224\n",
            "Epoch 5 Metrics -> Dice: 0.8783, IoU: 0.7862, Precision: 0.8743, Recall: 0.8893\n",
            "100% 130/130 [02:48<00:00,  1.30s/it]\n",
            "Epoch 6: Loss = 0.1067\n",
            "Epoch 6 Metrics -> Dice: 0.8919, IoU: 0.8073, Precision: 0.8936, Recall: 0.8940\n",
            "100% 130/130 [02:48<00:00,  1.29s/it]\n",
            "Epoch 7: Loss = 0.0949\n",
            "Epoch 7 Metrics -> Dice: 0.9015, IoU: 0.8227, Precision: 0.9044, Recall: 0.9006\n",
            "100% 130/130 [02:48<00:00,  1.30s/it]\n",
            "Epoch 8: Loss = 0.0889\n",
            "Epoch 8 Metrics -> Dice: 0.9070, IoU: 0.8314, Precision: 0.9116, Recall: 0.9042\n",
            "100% 130/130 [02:48<00:00,  1.30s/it]\n",
            "Epoch 9: Loss = 0.0838\n",
            "Epoch 9 Metrics -> Dice: 0.9113, IoU: 0.8385, Precision: 0.9180, Recall: 0.9061\n",
            "100% 130/130 [02:48<00:00,  1.30s/it]\n",
            "Epoch 10: Loss = 0.0800\n",
            "Epoch 10 Metrics -> Dice: 0.9142, IoU: 0.8432, Precision: 0.9226, Recall: 0.9070\n",
            "100% 130/130 [02:49<00:00,  1.30s/it]\n",
            "Epoch 11: Loss = 0.0762\n",
            "Epoch 11 Metrics -> Dice: 0.9174, IoU: 0.8487, Precision: 0.9259, Recall: 0.9102\n",
            "100% 130/130 [02:48<00:00,  1.30s/it]\n",
            "Epoch 12: Loss = 0.0741\n",
            "Epoch 12 Metrics -> Dice: 0.9194, IoU: 0.8521, Precision: 0.9274, Recall: 0.9130\n",
            "100% 130/130 [02:49<00:00,  1.30s/it]\n",
            "Epoch 13: Loss = 0.0720\n",
            "Epoch 13 Metrics -> Dice: 0.9212, IoU: 0.8550, Precision: 0.9275, Recall: 0.9165\n",
            "100% 130/130 [02:47<00:00,  1.29s/it]\n",
            "Epoch 14: Loss = 0.0689\n",
            "Epoch 14 Metrics -> Dice: 0.9244, IoU: 0.8604, Precision: 0.9299, Recall: 0.9204\n",
            "100% 130/130 [02:49<00:00,  1.30s/it]\n",
            "Epoch 15: Loss = 0.0658\n",
            "Epoch 15 Metrics -> Dice: 0.9279, IoU: 0.8662, Precision: 0.9308, Recall: 0.9261\n",
            "100% 130/130 [02:48<00:00,  1.29s/it]\n",
            "Epoch 16: Loss = 0.0626\n",
            "Epoch 16 Metrics -> Dice: 0.9312, IoU: 0.8720, Precision: 0.9329, Recall: 0.9307\n",
            "100% 130/130 [02:49<00:00,  1.30s/it]\n",
            "Epoch 17: Loss = 0.0590\n",
            "Epoch 17 Metrics -> Dice: 0.9352, IoU: 0.8789, Precision: 0.9357, Recall: 0.9354\n",
            "100% 130/130 [02:48<00:00,  1.30s/it]\n",
            "Epoch 18: Loss = 0.0558\n",
            "Epoch 18 Metrics -> Dice: 0.9389, IoU: 0.8853, Precision: 0.9373, Recall: 0.9410\n",
            "100% 130/130 [02:50<00:00,  1.31s/it]\n",
            "Epoch 19: Loss = 0.0528\n",
            "Epoch 19 Metrics -> Dice: 0.9426, IoU: 0.8919, Precision: 0.9409, Recall: 0.9449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run previous experiments using the new model"
      ],
      "metadata": {
        "id": "eqWeO_udG56Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running experiment 1 using mixed trained model"
      ],
      "metadata": {
        "id": "nNkBLUJExLQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running experiment with mixed-quality trained MedSAM\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_low_quality_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_low_split/test \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250728-mixedS/medsam_model_best.pth \\\n",
        "  --device cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi_-DJYaxUFb",
        "outputId": "491339b5-7282-4369-8a29-b4f1a3bdb2c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Found 28 image–mask pairs.\n",
            "100% 28/28 [00:15<00:00,  1.84it/s]\n",
            "Evaluation Results: {'dice': 0.4848139827538814, 'iou': 0.338812602184979, 'precision': 0.5526763663760254, 'recall': 0.5142066744821412}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running experiment 2 using mixed trained model"
      ],
      "metadata": {
        "id": "8Voyr4szHK03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mixed treained model\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_noise_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_low_split/test \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250728-mixedS/medsam_model_best.pth \\\n",
        "  --device cuda \\\n",
        "  --add_noise \\\n",
        "  --noise_variance 0.1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPTeXI3KtFem",
        "outputId": "78a53b10-136b-449e-b1e6-710a16234c4c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28 image–mask pairs.\n",
            "100% 28/28 [00:20<00:00,  1.35it/s]\n",
            "Evaluation Results: {'dice': 3.792401371609374e-05, 'iou': 1.8967681739204775e-05, 'precision': 0.8928571522263439, 'recall': 1.8967681745539863e-05}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_noise_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_low_split/test \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250728-mixedS/medsam_model_best.pth \\\n",
        "  --device cuda \\\n",
        "  --noise_variance 0.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqhPRmlGxH5e",
        "outputId": "e4ffeb2e-6329-4f11-88aa-0e6e06ec5db6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28 image–mask pairs.\n",
            "100% 28/28 [00:16<00:00,  1.66it/s]\n",
            "Evaluation Results: {'dice': 0.4848139827538814, 'iou': 0.338812602184979, 'precision': 0.5526763663760254, 'recall': 0.5142066744821412}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 4: Full C-TRUS Evaluation Using Fine-tuned Models"
      ],
      "metadata": {
        "id": "r_w35mr2zEbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since I have trained all the models and have conducted the experiments, I decided to also run Experiment 1 with the full C-TRUS dataset (like in zero-shot) as it may be useful for comparisons between tuning and non tuning approaches with MedSAM."
      ],
      "metadata": {
        "id": "jWav6nvZzR3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running experiment with high-quality trained MedSAM\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_low_quality_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_filtered_full \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250726-high/medsam_model_best.pth \\\n",
        "  --device cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-oVHn_9zqre",
        "outputId": "fda75dd1-5891-44fb-b021-feccbbab883e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Found 508 image–mask pairs.\n",
            "100% 508/508 [09:28<00:00,  1.12s/it]\n",
            "Evaluation Results: {'dice': 0.7259940419128494, 'iou': 0.6163883613953363, 'precision': 0.7644775034342253, 'recall': 0.7282553862867671}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running experiment with low-quality trained MedSAM\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_low_quality_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_filtered_full \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250728-lowS/medsam_model_best.pth \\\n",
        "  --device cuda"
      ],
      "metadata": {
        "id": "AJJm8c87z_H-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03432610-2fb7-46e5-e50d-fb2ff98eba06"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Found 508 image–mask pairs.\n",
            "100% 508/508 [04:19<00:00,  1.96it/s]\n",
            "Evaluation Results: {'dice': 0.6646983654351125, 'iou': 0.5244313150010069, 'precision': 0.7178379753569487, 'recall': 0.6688541508984649}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running experiment with mixed-quality trained MedSAM\n",
        "!python /content/drive/MyDrive/MedSAM/fine_tune_scripts/inference_low_quality_eval_per.py \\\n",
        "  -data_path /content/drive/MyDrive/MedSAM/data/npy_filtered_full \\\n",
        "  -model_path /content/drive/MyDrive/MedSAM/work_dir/MedSAM-ViT-B-20250728-mixedS/medsam_model_best.pth \\\n",
        "  --device cuda"
      ],
      "metadata": {
        "id": "FIFVNIA3z_Tb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea60f8c-fead-48f9-c25c-5e9d38fb6c0d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Found 508 image–mask pairs.\n",
            "100% 508/508 [04:15<00:00,  1.98it/s]\n",
            "Evaluation Results: {'dice': 0.7426482660578578, 'iou': 0.625330237987521, 'precision': 0.7850671473333216, 'recall': 0.7390815396261526}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of the Tests"
      ],
      "metadata": {
        "id": "Gjib25xeUEbG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results are further analyzed using wilcoxon signed-rank tests to see if the differences are significant. This was done using the wilcoxin_compare.py file and the results can be found in the Results_analysis jupyter notebook in my GitHub"
      ],
      "metadata": {
        "id": "Ey2gfY1iZtfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging Section"
      ],
      "metadata": {
        "id": "IHCol8rO982-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I realizedf that to make statistical analysis using the results, per image metrics are needed so I ran the same tests again but with the per image metrics being saved so that I can use it to back up my claims based on the results"
      ],
      "metadata": {
        "id": "LwM2aKu4nsGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# which checkpoint is which for the training\n",
        "MedSAM-ViT-B-20250727-1932 - mixed training \\\n",
        "MedSAM-ViT-B-20250727-1655 - low training \\\n",
        "MedSAM-ViT-B-20250726-1827 - high training \\\n",
        "\n",
        "MedSAM-ViT-B-20250727-mixed - mixed training \\\n",
        "MedSAM-ViT-B-20250727-low - low training \\\n",
        "\n",
        "# the final version for testing\n",
        "MedSAM-ViT-B-20250726-high - high training \\\n",
        "MedSAM-ViT-B-20250728-lowS --> fixed with split data \\\n",
        "MedSAM-ViT-B-20250728-mixedS --> fixed with split data\n",
        "\n"
      ],
      "metadata": {
        "id": "Lo-i6H_Huvas"
      }
    }
  ]
}